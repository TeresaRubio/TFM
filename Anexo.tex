\newenvironment{description2}{ \begin{description} \setlength{\itemsep}{0pt} \setlength{\parskip}{0pt}}{ \end{description} } 

{\setlength{\parindent}{0pt}
Software utilizado: fastQC (0.11.5), multiQC (0.9), seq\_crumbs (0.1.9), qiime (1.9.1).

Documentación:
\vspace*{-5mm}
\begin{itemize}
    	\addtolength{\itemsep}{-3mm}  % separacion entre items
\item \url{http://www.bioinformatics.babraham.ac.uk/projects/fastqc}
\item \url{http://multiqc.info}
\item \url{https://bioinf.comav.upv.es/seq_crumbs}
\item \url{http://qiime.org}
\end{itemize}

\section*{1. Descargar los datos en formato fastq desde ENA (EBI)}
En cada punto del \textit{pipeline} se crea un directorio para guardar los ficheros de salida de cada apartado. Como se genera una gran cantidad de datos, hay directorios que pueden ser borrados por el usuario si no son necesarios.
\begin{listing}[style=consola, numbers=none]
$ mkdir 01_Data_fastq
$ cd 01_Data_fastq
\end{listing}

Los datos se encuentran depositados en \textit{European Bioinformatics Institute (EBI) European Nucleotide Archive (ENA)} con el código de acceso ERP006059. Son 820 archivos con formato fastq. Se descargan los datos via FTP:
\begin{listing}[style=consola, numbers=none]
$ wget ftp://ftp.sra.ebi.ac.uk/vol1/ERA318/ERA318858/fastq/seqs_Saliva* # Todas las muestras de saliva
$ wget ftp://ftp.sra.ebi.ac.uk/vol1/ERA318/ERA318858/fastq/seqs_Stool* # Todas las muestras de intestino
\end{listing}


Descomprimir los datos:
\begin{listing}[style=consola, numbers=none]
$ gunzip *.gz
\end{listing}

También se descarga un fichero con los metadatos (\url{http://www.biomedcentral.com/content/supplementary/gb-2014-15-7-r89-S18.csv}), que serán necesarios para identificar las muestras que corresponden a cada individuo y a cada día.


\subsection*{ 1.1 Comprobar calidad de los datos con fastQC y multiQC}
FastQC es un software que permite hacer un control de calidad de forma sencilla. Con la opción ``*'' se detectan todos los archivos con formato ``.fastq" del directorio actual.
\begin{listing}[style=consola, numbers=none]
$ fastqc * #Los datos tienen la codificacion de calidad Sanger/Illumina 1.9
\end{listing}
Como hay 820 archivos, se utiliza multiQC para hacer un resumen de los datos analizados por fastQC. Con la opción ``.'' se detectan los archivos necesarios:
\begin{listing}[style=consola, numbers=none]
$ multiqc .
\end{listing}

\section*{ 2. Filtro de calidad utilizando seq\_crumbs 0.1.9}
Software desarrollado en Valencia que incorpora utilidades para procesar secuencias.
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ mkdir 02_Quality_filter
$ cd 02_Quality_filter
\end{listing}

Como se trabaja con 820 ficheros, hay que lanzar varios trabajos a la vez. En este grupo de investigación existen cuatro servidores llamados SOM (1-4) y utilizan un sistema de colas para no colapsar las máquinas por todos los usuarios. 
Modo de uso:
\begin{center}
  clusterlauncher -N ejemplo -n 1 -s som1 /bin/sleep 240 (lanza 1 proceso secuencial al sistema de colas llamado ``ejemplo'' para ejecutarlo en som1)
\end{center}
Opciones:
\vspace*{-5mm}
\begin{description2}
    \item  -N : nombre del trabajo.
    \item  -n : número de procesos paralelos.
    \item  -s : servidor/es donde lanzar el trabajo.
\end{description2}

Para filtrar por calidad se utiliza el \textit{script filter\_by\_quality} de seq\_crumbs:
\vspace*{-5mm}
\begin{description2}
    \item  -q, --threshold : umbral de calidad.
    \item  -o, --outfile : nombre del fichero de salida.
\end{description2}

\begin{listing}[style=consola, numbers=none]
$ for i in ../01_Data_fastq/seqs_S*.fastq; 
do clusterlauncher -N ${i:22} -n 1 -s som1 filter_by_quality $i -q 30 -o q30_${i:22};
done
\end{listing}

\section*{ 3. De .fastq a .fasta con qiime}
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ mkdir 03_Data_fasta
$ cd 03_Data_fasta
\end{listing}

Qiime utiliza el formato fasta como entrada, así que incorpora un \textit{script} para cambiar de formatos. Éste produce 2 ficheros: uno con secuencias (.fna) y otro con calidades (.qual).

Para pasar a formato fasta se utiliza \textit{convert\_fastaqual\_fastq.py}:
\vspace*{-5mm}
\begin{description2}
    \item  -c, --conversion\_type : tipo de conversión (\textit{fastaqual\_to\_fastq} o \textit{fastq\_to\_fastaqual})
    \item  -f, --fasta\_file\_path : fichero de entrada (fasta o fastq)
    \item  -a, --ascii\_increment : número a sumar (restar si se parte desde FASTQ) a la puntuación de calidad para obtener el carácter ASCII
    \item  --full\_fasta\_headers : para incluir las cabeceras de los archivos FASTA en el fichero de salida (en lugar de simplemente la etiqueta de secuencia).
\end{description2}

\begin{listing}[style=consola, numbers=none]
$ for i in ../02_Quality_filter/q30_S*.fastq;
do clusterlauncher -N ${i:21} -n 1 -s som1 convert_fastaqual_fastq.py -c fastq_to_fastaqual -f $i -a 64 --full_fasta_headers;
done
\end{listing}

Nótese que se utiliza la opción ``-a'' porque los datos de partida tienen la codificacion de calidad Sanger/Illumina 1.9.

\section*{ 4. Eliminar quimeras}
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ mkdir 04_Chimeras
$ cd 04_Chimeras
\end{listing}

Las quimeras son artefactos producidos durante el proceso de PCR. Se trata de secuencias de ADN que contienen mezclas de otras secuencias. Qiime permite eliminarlas mediante dos pasos: primero identificar y luego limpiar las quimeras.

1) Identificar quimeras con \textit{identify\_chimeric\_seqs.py}:
\vspace*{-5mm}
\begin{description2}
    \item  -i, --input\_fasta\_fp : fichero de entrada en formato fasta.
    \item  -m, --chimera\_detection\_method : método de detección de quimeras (\textit{blast\_fragments}, \textit{ChimeraSlayer} o \textit{usearch61}).
    \item  -r, --reference\_seqs\_fp : ruta a la base de datos de referencia.
    \item  -o, --output\_fp : nombre del directorio de salida.
\end{description2}

\begin{listing}[style=consola, numbers=none]
$ for i in ../03_Data_fasta/q30_*.fna;
do
clusterlauncher -N ${i:17} -n 1 identify_chimeric_seqs.py -i $i -m usearch61 -r /software/databases/gg_13_8_otus/rep_set/97_otus.fasta -o chimeras_${i:17};
done
\end{listing}

2) Limpiar secuencias quimera con \textit{filter\_fasta.py}:
\vspace*{-5mm}
\begin{description2}
    \item  -f, --input\_fasta\_fp : fichero de entrada en formato fasta.
    \item  -o, --output\_fasta\_fp : fichero de salida en formato fasta.
    \item  -s, --seq\_id\_fp : lista de identificadores de secuencias que deben retenerse.
    \item  -n, --negate : desecha los identificadores de secuencia pasados en lugar de mantenerlos.
\end{description2}

\begin{listing}[style=consola, numbers=none]
$ for i in ../03_Data_fasta/q30_*.fna;
do
clusterlauncher -N non_chimeric_${i:17} -n 1 filter_fasta.py -f $i -o non_chimeric_${i:17} -s chimeras_${i:17}/chimeras.txt -n;
done
\end{listing}

NOTA: es muy importante en este paso usar ``-n'' porque le dice al \textit{script} que descarte todas las secuencias que le hemos pasado a través de la opción ``-s'', es decir, que elimine las quimeras. Esto se hace así porque el \textit{script identify\_chimeric\_seqs.py} ofrece una lista de las secuencias quiméricas y no de las secuencias no quiméricas.

\subsection*{ 4.1 Eliminar ficheros con bajo número de lecturas}
Se hace un conteo del número de \textit{reads} por fichero tras todo el preprocesado y se guarda en un fichero adicional:
\begin{listing}[style=consola, numbers=none]
$ for i in non_chimeric_q30_S*.fna; do r=$(awk '{s++}END{print s/2}' $i) ; echo $r $i | column -t; done > numero_reads.txt
\end{listing}

Se muestran las 25 primeras líneas del fichero ordenado:
\begin{lstlisting}[style=Python]
1	non_chimeric_q30_Stool448.1259730.fastq.fna
2	non_chimeric_q30_Stool196.1259770.fastq.fna
4	non_chimeric_q30_Stool13.1259916.fastq.fna
5	non_chimeric_q30_Saliva267.1260193.fastq.fna
8	non_chimeric_q30_Stool217.1260272.fastq.fna
8	non_chimeric_q30_Stool85.1260354.fastq.fna
29	non_chimeric_q30_Stool63.1259769.fastq.fna
31	non_chimeric_q30_Stool120.1259849.fastq.fna
39	non_chimeric_q30_Stool147.1260039.fastq.fna
54	non_chimeric_q30_Stool36.1259652.fastq.fna
1006	non_chimeric_q30_Stool453.1260253.fastq.fna
1423	non_chimeric_q30_Stool92.1259811.fastq.fna
1738	non_chimeric_q30_Stool452.1259809.fastq.fna
2501	non_chimeric_q30_Stool384.1259728.fastq.fna
2772	non_chimeric_q30_Stool340.1260381.fastq.fna
3554	non_chimeric_q30_Stool4.1260013.fastq.fna
4026	non_chimeric_q30_Stool343.1259705.fastq.fna
4493	non_chimeric_q30_Stool454.1260333.fastq.fna
6395	non_chimeric_q30_Stool382.1260123.fastq.fna
7462	non_chimeric_q30_Stool345.1259808.fastq.fna
11248	non_chimeric_q30_Stool455.1260157.fastq.fna
11459	non_chimeric_q30_Stool372.1259688.fastq.fna
11676	non_chimeric_q30_Stool326.1260401.fastq.fna
11859	non_chimeric_q30_Stool138.1260296.fastq.fna
13512	non_chimeric_q30_Stool373.1259958.fastq.fna
\end{lstlisting}


Se eliminan manualmente los 20 ficheros que contienen menos de 10000 lecturas.

\section*{ 5. Seleccionar OTUs}
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ mkdir 05_OTUs
$ cd 05_OTUs
\end{listing}

OTU son las siglas en inglés de \textit{Operational Taxonomic Unit}. Es una unidad de clasificación para individualizar los taxones del estudio.

Para seleccionar OTUs se utiliza \textit{pick\_open\_reference\_otus.py}:
\vspace*{-5mm}
\begin{description2}
    \item  -i, --input\_fps : fichero de secuencias de entrada.
    \item  -o, --output\_dir : directorio de salida.
    \item  -p : parámetos para introducir en los distintos pasos del \textit{script}. 
\end{description2}

En este caso se utiliza un fichero auxiliar llamado ``uc\_fast\_params.txt'' con los parámetros que tiene el siguiente contenido:
\begin{lstlisting}[style=Python]
pick_otus:enable_rev_strand_match True
\end{lstlisting}

Esta instrucción sirve para que tenga en cuenta ambos sentidos de lectura de cada secuencia cuando haga el ``pick otus''.

\begin{listing}[style=consola, numbers=none]
$ for i in ../04_Chimeras/non_chimeric_*.fna;
do
clusterlauncher -N otus_${i:15} -s som1 -n 1 pick_open_reference_otus.py -i $i -o "otus_"${i:15} -p uc_fast_params.txt;
done
\end{listing}

\section*{ 6. Resumir taxones}
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ mkdir 06_Summarize_taxa
$ cd 06_Summarize_taxa
\end{listing}

El \textit{script summarize\_taxa.py} proporciona información resumida de la representación de los grupos taxonómicos dentro de cada muestra:
\vspace*{-5mm}
\begin{description2}
    \item  -i, --otu\_table\_fp : fichero de entrada (tabla OTU que contiene información taxonómica).
    \item  -o, --output\_dir : directorio de salida.
    \item  -L, --level : nivel taxonómico para el que se proporciona la información resumida. [Niveles: 1 (Reino), 2 (Fílum), 3 (Clase), 4 (Orden), 5 (Familia), 6 (Género), 7 (Especie)]
    \item  --suppress\_biom\_table\_output : la tabla de taxones con formato BIOM no se creará en el directorio de salida.
    \item  -a, --absolute\_abundance : para obtener como resultado una tabla con la abundancia absoluta de cada grupo taxonómico. Por defecto (si no se pone ``-a''), este \textit{script} utiliza abundancia relativa.
\end{description2}

\begin{listing}[style=consola, numbers=none]
$ for i in ../05_OTUs/otus_non_chimeric_q30_*/otu_table_mc2_w_tax.biom;
do
clusterlauncher -N ${i:11:38} -n 1 summarize_taxa.py -i $i -o absolute_L6_${i:11:-25} -L 6 --suppress_biom_table_output -a;
done
\end{listing}

\vspace*{-5mm}
\section*{ 7. Datos para complexCruncher}
Agrupar las tablas de abundancia en 3 directorios según el tipo de muestra: donante A saliva, donante A intestino y donante B intestino. Para muestras de saliva es fácil porque se distinguen los ficheros por su nombre:
\begin{listing}[style=consola, numbers=none]
$ mkdir Saliva_DonorA
$ for i in *q30_Saliva*; do 
  mv $i/otu_table_mc2_w_tax_L6.txt Saliva_DonorA/$i; 
  rm -r $i;
done
\end{listing}

Para muestras de intestino hay que separar entre sujeto A y B. Para ello se crea un fichero auxiliar que contiene los nombres de las tablas de abundancia del sujeto B. Ese fichero se obtiene a partir de los metadatos simplemente ordenando la tabla por la columna 18 ``Description'' y guardando los elementos de la primera columna que tengan la descripción ``DonorB Stool''. Es necesario que el fichero auxiliar se encuentre en el directorio actual de trabajo.

\begin{listing}[style=consola, numbers=none]
$ mkdir Stool_DonorB
$ for i in *q30_Stool*;
do 
    for line in $(cat Stool_DonorB.txt); 
        do if [ $line = ${i:34} ]; then
	    mv $i/otu_table_mc2_w_tax_L6.txt Stool_DonorB/$i; 
            rm -r $i;
            fi;
done;
done
\end{listing}

El resto de tablas que quedan son de intestino de Sujeto A. Así que se mueven a su carpeta con la misma estrategia utilizada en saliva:
\begin{listing}[style=consola, numbers=none]
$ mkdir Stool_DonorA
$ for i in *q30_Stool*; do 
    mv $i/otu_table_mc2_w_tax_L6.txt Stool_DonorA/$i; 
    rm -r $i;
done
\end{listing}

En este punto se tienen 3 directorios con mútliples ficheros, cada uno de ellos es una tabla de abundancia para cada día. La idea es juntar todos esas tablas pequeñas en una tabla grande con entradas únicas que resuma todas las abundancias a lo largo del año.

Además, para pasos posteriores se necesita subdividir esa tabla grande final en subtablas que abarcan distintos intervalos de tiempo. Todo ello lo hace un \textit{script} implementado en Python. Se muestra como ejemplo el \textit{script} de saliva A:

\begin{lstlisting}[style=Python]
import glob
import pandas as pd


# Fichero auxiliar con el nombre de los ficheros a añadir
sup_f = open("Saliva_samples.txt","r")
sup_f_text = sup_f.read().split("\n")
sup_f.close()

# Generar lista de tablas por día
list_of_dic = []
for i in sup_f_text:
    try:
        # Ficheros de abundancia absoluta:
        file = "absolute_L6_" + i
        f_in = open(file, "r")
        text = f_in.read()
        f_in.close()
        
        # Quitar cabecera
        sentences = text.split("\n")
        sentences = "\t".join(sentences)
        sentences = sentences.split("\t")
        
        sample = sentences[2]
        sentences = sentences[3:]
        
        # Crear un diccionario que sirve como tabla final
        otu = []
        abundance = []
        
        for j in range(len(sentences)):
            if j%2 == 0:
                otu.append(sentences[j])
            else:
                abundance.append(float(sentences[j]))
            
        raw_data = {
                "otu_id": otu,
                sample: abundance} 
        
        df_a = pd.DataFrame(raw_data, columns = ["otu_id", sample])
        list_of_dic.append(df_a)
    except:
        print("No se encuentra el fichero" + str(i))

# Crear una tabla única final
f_table = list_of_dic[0]

for k in range(1, len(list_of_dic)):
    f_table = pd.merge(f_table, list_of_dic[k], on="otu_id", how="outer")


# Dividir tabla final en intervalos de tiempo y guardar cada subtabla en una hoja excel
df2 = f_table.iloc[:,1:40]
df2.insert(0, "otu_id",value=f_table.iloc[:,0])
df3 = f_table.iloc[:,40:75]
df3.insert(0, "otu_id",value=f_table.iloc[:,0])
df4 = f_table.iloc[:,75:203]
df4.insert(0, "otu_id",value=f_table.iloc[:,0])
df5 = f_table.iloc[:,203:]
df5.insert(0, "otu_id",value=f_table.iloc[:,0])

# Formatear salida
pd.set_option("expand_frame_repr", False)

# Escribir cada dataframe en una hoja Excel diferente
writer = pd.ExcelWriter('HostLifeStyle_SalivaA_absoluta.xlsx')
f_table.to_excel(writer, sheet_name="SalivaA", index = True, na_rep = 0)
df2.to_excel(writer, sheet_name="h_SalivaA_Day26to69",index = False, na_rep = 0)
df3.to_excel(writer, sheet_name="SalivaA_Day72to122",index = False, na_rep = 0)
df4.to_excel(writer, sheet_name="h_SalivaA_Day123to257",index = False, na_rep = 0)
df5.to_excel(writer, sheet_name="h_SalivaA_Day258to364",index = False, na_rep = 0)

# Cerrar el escritor Pandas Excel y guardar el fichero
writer.save()
\end{lstlisting}

Los \textit{scripts} para intestino A e intestino B pueden encontrarse en el material suplementario o en la dirección \url{https://github.com/TeresaRubio/TFM/tree/a/Scripts} con los nombres ``merge\&split\_stoolA.py'' y ``merge\&split\_stoolB.py'', respectivamente.

Se ejecuta un \textit{script} por directorio y se obtienen las 3 tablas:
\begin{listing}[style=consola, numbers=none]
$ cd Saliva_DonorA
$ python merge&split_salivaA.py
\end{listing}
\begin{listing}[style=consola, numbers=none]
$ cd..
$ cd Stool_DonorA
$ python merge&split_stoolA.py
\end{listing}
\begin{listing}[style=consola, numbers=none]
$ cd ..
$ cd Stool_DonorB
$ python merge&split_stoolB.py
\end{listing}
}
